{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_features(X_train, X_test):\n",
    "    scaler = StandardScaler()\n",
    "    scaler.fit(X_train)\n",
    "    X_train_norm = scaler.transform(X_train)\n",
    "    X_test_norm = scaler.transform(X_test)\n",
    "    return X_train_norm, X_test_norm\n",
    "\n",
    "def PCC(x, y):\n",
    "    A = x - np.mean(x)\n",
    "    B = y - np.mean(y)\n",
    "    return np.dot(A, B) / np.sqrt(np.dot(A, A) * np.dot(B, B))\n",
    "\n",
    "def RMSE(x, y):\n",
    "    m = x.shape[0]\n",
    "    return np.sqrt(np.dot(x - y, x - y) / m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecisionTreeRegressor():\n",
    "    def __init__(self, max_depth = 5, current_depth = 1, max_features = None):\n",
    "        self.max_depth = max_depth\n",
    "        self.current_depth = current_depth\n",
    "        self.left_tree = None\n",
    "        self.right_tree = None\n",
    "        self.max_features = max_features\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        self.n_features = X.shape[1]\n",
    "        self.n_samples = X.shape[0]\n",
    "        if self.current_depth <= self.max_depth:\n",
    "            self.rss = self.rss_calculation(self.y)\n",
    "            self.best_feature_id, self.best_gain, self.best_split_value = self.find_best_split()\n",
    "            if self.best_gain > 0:\n",
    "                self.split_trees()\n",
    "\n",
    "    def split_trees(self):\n",
    "        self.left_tree = DecisionTreeRegressor(max_depth = self.max_depth, current_depth = self.current_depth + 1)\n",
    "        self.right_tree = DecisionTreeRegressor(max_depth = self.max_depth, current_depth = self.current_depth + 1)\n",
    "        best_feature_values = self.X[:, self.best_feature_id]\n",
    "        left_indices = np.where(best_feature_values < self.best_split_value)\n",
    "        right_indices = np.where(best_feature_values >= self.best_split_value)\n",
    "        left_tree_X, left_tree_y = self.X[left_indices], self.y[left_indices]\n",
    "        right_tree_X, right_tree_y = self.X[right_indices], self.y[right_indices]\n",
    "        self.left_tree.fit(left_tree_X, left_tree_y)\n",
    "        self.right_tree.fit(right_tree_X, right_tree_y)\n",
    "\n",
    "    def find_best_split(self):\n",
    "        best_feature_id = None\n",
    "        best_gain = 0\n",
    "        best_split_value = None\n",
    "        if self.max_features is None:\n",
    "            for feature_id in range(self.n_features):\n",
    "                current_gain, current_split_value = self.find_best_split_one_feature(feature_id)\n",
    "                if current_gain is None:\n",
    "                    continue\n",
    "                if best_gain < current_gain:\n",
    "                    best_feature_id = feature_id\n",
    "                    best_gain = current_gain\n",
    "                    best_split_value = current_split_value\n",
    "        elif self.max_features == 'sqrt':\n",
    "            rng = np.random.default_rng()\n",
    "            sampled_features = rng.choice(self.X.shape[1], int(np.sqrt(self.X.shape[1])), replace = False)\n",
    "            for feature_id in sampled_features:\n",
    "                current_gain, current_split_value = self.find_best_split_one_feature(feature_id)\n",
    "                if current_gain is None:\n",
    "                    continue\n",
    "                if best_gain < current_gain:\n",
    "                    best_feature_id = feature_id\n",
    "                    best_gain = current_gain\n",
    "                    best_split_value = current_split_value\n",
    "        return best_feature_id, best_gain, best_split_value\n",
    "\n",
    "    def find_best_split_one_feature(self, feature_id):\n",
    "        feature_values = self.X[:, feature_id]\n",
    "        unique_feature_values = np.unique(feature_values)\n",
    "        best_gain = 0.0\n",
    "        best_split_value = None\n",
    "        if len(unique_feature_values) == 1:\n",
    "            return best_gain, best_split_value\n",
    "        for fea_val in unique_feature_values:\n",
    "            left_indices, right_indices = np.where(feature_values < fea_val), np.where(feature_values >= fea_val)\n",
    "            left_tree_y, right_tree_y = self.y[left_indices], self.y[right_indices]\n",
    "            left_rss, right_rss = self.rss_calculation(left_tree_y), self.rss_calculation(right_tree_y)\n",
    "            current_gain = self.rss - left_rss - right_rss\n",
    "            if best_gain < current_gain:\n",
    "                best_gain = current_gain\n",
    "                best_split_value = fea_val\n",
    "        return best_gain, best_split_value\n",
    "\n",
    "    def rss_calculation(self, y):\n",
    "        if y.size == 0 or y is None:\n",
    "            return 0\n",
    "        return np.sum((y - np.mean(y))**2)\n",
    "\n",
    "    def predict(self, X_test):\n",
    "        n_test = X_test.shape[0]\n",
    "        ypred = np.zeros(n_test, dtype = int)\n",
    "        for i in range(n_test):\n",
    "            ypred[i] = self.tree_propogation(X_test[i])\n",
    "        return ypred\n",
    "\n",
    "    def tree_propogation(self, feature):\n",
    "        if self.is_leaf_node():\n",
    "            return self.predict_label()\n",
    "        if feature[self.best_feature_id] < self.best_split_value:\n",
    "            child_tree = self.left_tree\n",
    "        else:\n",
    "            child_tree = self.right_tree\n",
    "        return child_tree.tree_propogation(feature)\n",
    "\n",
    "    def predict_label(self):\n",
    "        return np.mean(self.y)\n",
    "\n",
    "    def is_leaf_node(self):\n",
    "        return self.left_tree is None "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class random_forest_regressor:\n",
    "    def __init__(self, n_estimators = 10):\n",
    "        self.n_estimators = n_estimators\n",
    "        self.forest = []\n",
    "        for i in range(self.n_estimators):\n",
    "            self.forest.append(DecisionTreeRegressor(max_depth = 20, max_features='sqrt'))\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        '''bagging'''\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        self.N = X.shape[1]\n",
    "        self.M = X.shape[0]\n",
    "\n",
    "        self.trees_idx = np.random.randint(0, self.M, size = (self.n_estimators, self.M))\n",
    "        for i, itree in enumerate(self.forest):\n",
    "            itree.fit(self.X[self.trees_idx[i]], self.y[self.trees_idx[i]])\n",
    "            print(\"The {}th tree is built\".format(i))\n",
    "\n",
    "    def predict(self, Xtest):\n",
    "        n_test = Xtest.shape[0]\n",
    "        ypred = np.zeros((self.n_estimators, n_test))\n",
    "        for i, itree in enumerate(self.forest):\n",
    "            ypred[i, :] = itree.predict(Xtest)\n",
    "        return np.mean(ypred, axis = 0) # stats.mode get the most common element along a certain axis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GradientBoostingRegressor():\n",
    "    def __init__(self, n_estimators = 10, lr = 1.):\n",
    "        self.n_estimators = n_estimators\n",
    "        self.lr = lr\n",
    "        self.regressors = []\n",
    "        for i in range(self.n_estimators):\n",
    "            self.regressors.append(DecisionTreeRegressor())\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        y_pred = np.full(y.size, np.mean(y))\n",
    "        self.y_pred0 = np.mean(y)\n",
    "        residue = y - y_pred\n",
    "\n",
    "        for i in np.arange(self.n_estimators):\n",
    "            self.regressors[i].fit(X, residue)\n",
    "            ipred = self.regressors[i].predict(X)\n",
    "            y_pred = y_pred + self.lr * ipred\n",
    "            residue = y - y_pred\n",
    "\n",
    "    def predict(self, Xtest):\n",
    "        y_pred = np.full(Xtest.shape[0], self.y_pred0)\n",
    "        for i in np.arange(self.n_estimators):\n",
    "            y_pred += self.lr * (self.regressors[i].predict(Xtest))\n",
    "        return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(108, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.layers(x)\n",
    "\n",
    "def train(model, device, train_loader, optimizer, epoch):\n",
    "    model.train()\n",
    "    current_loss = 0.0\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        data, target = data.float(), target.float()\n",
    "        target = target.reshape((target.shape[0], 1))\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = loss_function(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        current_loss += loss.item()\n",
    "\n",
    "        if epoch % 5 == 0:\n",
    "            print('Train Epoch: {} [{}/{}]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(data), len(train_loader.dataset), loss.item()))\n",
    "            current_loss = 0.0\n",
    "\n",
    "def test(model, device, epoch, test_loader):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    yvals = test_loader.dataset.yvals().detach().numpy()\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (data, target) in enumerate(test_loader):\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            data, target = data.float(), target.float()\n",
    "            target = target.reshape((target.shape[0], 1))\n",
    "            \n",
    "            output = model(data)\n",
    "            test_loss += loss_function(output, target).item()\n",
    "\n",
    "            if batch_idx == 0:\n",
    "                preds = output.detach().numpy()\n",
    "            else:\n",
    "                preds = np.append(preds, output.detach().numpy())\n",
    "            \n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    \n",
    "    if epoch %5 == 0:\n",
    "        print('\\n Test set: Average loss: {:.4f}'.format(test_loss))\n",
    "        print('RMSE is {} and PCC is {}'.format(RMSE(preds, yvals), PCC(preds, yvals)))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('Binding_energy_train.csv')\n",
    "f_train = df_train.values\n",
    "df_test = pd.read_csv('Binding_energy_test.csv')\n",
    "f_test = df_test.values\n",
    "\n",
    "Xtrain = f_train[:,1:]\n",
    "ytrain = f_train[:,0]\n",
    "Xtest = f_test[:,1:]\n",
    "ytest = f_test[:,0]\n",
    "\n",
    "Xtrain_norm, Xtest_norm = normalize_features(Xtrain, Xtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The 0th tree is built\n",
      "The 1th tree is built\n",
      "The 2th tree is built\n",
      "The 3th tree is built\n",
      "The 4th tree is built\n",
      "The 5th tree is built\n",
      "The 6th tree is built\n",
      "The 7th tree is built\n",
      "The 8th tree is built\n",
      "The 9th tree is built\n",
      "For Random Forest, the RMSE is 1.55 and the PCC is 0.76\n"
     ]
    }
   ],
   "source": [
    "RF = random_forest_regressor(n_estimators = 10)\n",
    "RF.fit(Xtrain_norm, ytrain)\n",
    "ypred = RF.predict(Xtest_norm)\n",
    "rmse = RMSE(ypred, ytest)\n",
    "pcc = PCC(ypred, ytest)\n",
    "\n",
    "print(\"For Random Forest, the RMSE is {:.2f} and the PCC is {:.2f}\".format(rmse, pcc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y sizes are (290,) and (290,)\n",
      "For Gradient Boosting, the RMSE is 1.66 and the PCC is 0.66\n"
     ]
    }
   ],
   "source": [
    "GBTR = GradientBoostingRegressor(n_estimators = 10)\n",
    "GBTR.fit(Xtrain_norm, ytrain)\n",
    "ypred = GBTR.predict(Xtest_norm)\n",
    "\n",
    "rmse = RMSE(ypred, ytest)\n",
    "pcc = PCC(ypred, ytest)\n",
    "\n",
    "print(\"For Gradient Boosting, the RMSE is {:.2f} and the PCC is {:.2f}\".format(rmse, pcc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 5 [0/3767]\tLoss: 1.481058\n",
      "Train Epoch: 5 [500/3767]\tLoss: 1.500421\n",
      "Train Epoch: 5 [1000/3767]\tLoss: 1.430969\n",
      "Train Epoch: 5 [1500/3767]\tLoss: 1.587077\n",
      "Train Epoch: 5 [2000/3767]\tLoss: 1.531697\n",
      "Train Epoch: 5 [2500/3767]\tLoss: 1.544250\n",
      "Train Epoch: 5 [3000/3767]\tLoss: 1.391415\n",
      "Train Epoch: 5 [1869/3767]\tLoss: 1.514726\n",
      "\n",
      " Test set: Average loss: 0.1141\n",
      "RMSE is 2.1425028002038635 and PCC is 0.4126030743217336\n",
      "Train Epoch: 10 [0/3767]\tLoss: 1.243402\n",
      "Train Epoch: 10 [500/3767]\tLoss: 1.294141\n",
      "Train Epoch: 10 [1000/3767]\tLoss: 1.344394\n",
      "Train Epoch: 10 [1500/3767]\tLoss: 1.286102\n",
      "Train Epoch: 10 [2000/3767]\tLoss: 1.295546\n",
      "Train Epoch: 10 [2500/3767]\tLoss: 1.285979\n",
      "Train Epoch: 10 [3000/3767]\tLoss: 1.356080\n",
      "Train Epoch: 10 [1869/3767]\tLoss: 1.276915\n",
      "\n",
      " Test set: Average loss: 0.1023\n",
      "RMSE is 1.948965366797737 and PCC is 0.48501413072452654\n",
      "Train Epoch: 15 [0/3767]\tLoss: 1.238486\n",
      "Train Epoch: 15 [500/3767]\tLoss: 1.215631\n",
      "Train Epoch: 15 [1000/3767]\tLoss: 1.233347\n",
      "Train Epoch: 15 [1500/3767]\tLoss: 1.248138\n",
      "Train Epoch: 15 [2000/3767]\tLoss: 1.224925\n",
      "Train Epoch: 15 [2500/3767]\tLoss: 1.249161\n",
      "Train Epoch: 15 [3000/3767]\tLoss: 1.257776\n",
      "Train Epoch: 15 [1869/3767]\tLoss: 1.112514\n",
      "\n",
      " Test set: Average loss: 0.0997\n",
      "RMSE is 1.8909643868332886 and PCC is 0.5484071662888044\n"
     ]
    }
   ],
   "source": [
    "class InitializeDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, X, y, scale_data = True):\n",
    "        if not torch.is_tensor(X) and not torch.is_tensor(y):\n",
    "            if scale_data:\n",
    "                X = StandardScaler().fit_transform(X)\n",
    "            self.X = torch.from_numpy(X)\n",
    "            self.y = torch.from_numpy(y)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        return self.X[i], self.y[i]\n",
    "\n",
    "    def yvals(self):\n",
    "        return self.y\n",
    "\n",
    "device = torch.device(\"cpu\")\n",
    "train_data = InitializeDataset(Xtrain, ytrain)\n",
    "test_data = InitializeDataset(Xtest, ytest)\n",
    "train_loader = torch.utils.data.DataLoader(dataset = train_data, batch_size = 500, shuffle = True)\n",
    "test_loader = torch.utils.data.DataLoader(dataset = test_data, batch_size = 16, shuffle = False)\n",
    "\n",
    "model = MLP().to(device)\n",
    "loss_function = nn.L1Loss()\n",
    "optimizer = optim.Adam(model.parameters(), lr = 0.01, amsgrad = False)\n",
    "for epoch in range(1, 15 + 1):\n",
    "    train(model, device, train_loader, optimizer, epoch)\n",
    "    test(model, device, epoch, test_loader)\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "850e57bc10b00bb94f5aeb321281c884d0c0fe9ac1e994f73e1eadb36de5a029"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('ENV')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
